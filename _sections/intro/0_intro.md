Scientists work in isolation at every scale, reinventing the wheel in
parallel. Our knowledge dissemination systems are as nimble as static pdfs[^socialmediaflirting] served by an extractive publishing turned surveillance industry we can't seem to quit. Experimental instrumentation except for that at the polar extremes of technological complexity or simplicity is designed and built custom, locally, and on-demand[^disciplinecaveat]. Software for performing experiments is a patchwork of libraries that satisfy some of the requirements of the experiment, sewn together by some uncommented script written years ago by a grad student who left the lab long-since. The technical knowledge to build both instrumentation and software is fragmented and unavailable as it sifts through the funnels of word-limited methods sections and never-finished documentation. Our data is born into this world without coherent form to speak of, indexable only by passively-encrypted notes in a paper lab notebook, and analyzed once before being mothballed in ignominy on some unlabeled external drive. 

These problems are typically treated in isolation, but all are symptomatic of a broader deficit in **digital infrastructure** for science. Every routine need that requires heavy technical development, an appeal to a hostile publishing system, or yet another platform subscription is an indicator that infrastructural deficits *define the daily reality of science.* We *should* be able to easily store, share, and search for data; be able to organize and communicate with each other; be able to write and review our work, but we are hemmed in on all sides by looming tech profiteers and chasms of underdevelopment.

If the term infrastructure conjures images of highways and plumbing, then surely digital infrastructure would be flattered at the association. Roughly following Star and Ruhleder's (1996) dimensions {% cite starStepsEcologyInfrastructure1996 %}, by analogy they illustrate many of its promises and challenges: when designed to, it can make practically impossible things trivial, allowing the development of cities by catching water where it lives and snaking it through tubes and tunnels sometimes directly into your kitchen. Its absence or failure is visible and impactful, as in the case of power outages. There is no guarantee that it "optimally" satisfies some set of needs for the benefit of the greatest number of people, as in the case of the commercial broadband duopolies. It exists not only as its technical reality, but also as an embodied and shared set of social practices, and so even when it does exist its form is not inevitable or final; as in the case of bottled water producers competing with municipal tap water on a behavioral basis despite being dramatically less efficient and more costly. Finally it is not socially or ethically neutral, and the impact of failure to build or maintain it is not equally shared, as in the expression of institutional racism that was the Flint, Michigan water crisis {% cite michicancivilrightscommissionFlintWaterCrisis2017 %}. 

Infrastructural deficits are not our inevitable and eternal fate, but the course of infrastructuring is far from certain. It is not the case that "scientific digital infrastructure" will rise from the sea monolithically as a natural result of more development time and funding, but instead has many possible futures{% cite mirowskiFutureOpenScience2018 %}, each with their own advocates and beneficiaries. Without concerted and strategic development based on a shared and liberatory ethical framework, science will continue to follow the same path as other domains of digital technology down the dark road of platform capitalism. The prize of owning the infrastructure that the practice of science is built on is too great, and it is not hard to imagine tech behemoths buying out the emerging landscape of small scientific-software-as-a-service startups and selling subscriptions to Science Prime. 

The possibility of future capture of nascent infrastructure is still too naive a framing: operating as obligate brokers of (usually surveillance) data{% cite pooleySurveillancePublishing2021 zuboffBigOtherSurveillance2015 warkCapitalDeadThis2021 %}, prestige, and computational resources naturally relies on *displacing* the possibility of alternative infrastructure. Our predicament is doubly difficult: we both have digital infrastructural deficits, but are also being actively *deinfrastructured.* The harms of deinfrastructuring are bidirectional, comprising both the missed opportunities from decades of free knowledge exchange, and the impacts of the informational regime that exists in its place. One can only imagine what the state of science and medicine might be if NIH's 1999 push to displace for-profit journals{% cite robertsBuildingGenBankPublished2001 varmusArtPoliticsScience2009 klingRealStakesVirtual2004 markovitzBiomedicineElectronicPublishing2000 %} had succeeded and we had more than 20 years of infrastructural development built atop a fundamentally free system of scientific knowledge. Instead, our failure to seize the digital infrastructure of science has led to a system where what should be our shared intellectual heritage is yoked to the profit engine of surveillance conglomerates (formerly known as publishers) {% cite pooleySurveillancePublishing2021 franceschi-bicchieraiAcademicJournalClaims2022 %} that repackage it along with a deluge of mined personal data in a circular economy of control {% cite brembsAlgorithmicEmploymentDecisions2021 appleWatchOSDeliversNew2022 douressProfessionalMatchingService2007 %} that makes us directly complicit in the worst abuses of informational capitalism {% cite biddleICESearchedLexisNexis2022 biddleLexisNexisProvideGiant2021 lamdanDefundPoliceDefund2020 lamdanLibrarianshipCrossroadsICE2019 westDataCapitalismRedefining2019 %}. 

We need to move beyond conceptualizing the problems of scientific infrastructure as being unique to science, a sighing hope for some future that "might be nice" to have (built by an always-anonymous "*someone else*"), but one to be pursued gradually after staid and cautious scholars are convinced no risk will come to our precious systems of prestige and peer review. We need to start seeing ours as one of many stories in the digital enclosure movement where adversarial economic entities take ownership of basic digital infrastructure and wipe out a domain of knowledge work, reducing it to a captive market and content farm {% cite warkCapitalDeadThis2021 warkHackerManifesto2004 %}. We need to see taking control of our digital infrastructure as *essential* to the continued existence of science as we know it.

This paper is an argument that **decentralized** digital infrastructure[^nocrypto] is the best means of alleviating the harms of infrastructural deficits and building a digital landscape that supports, rather than extracts from science. I will draw from several disciplines and knowledge communities, across and outside academia to articulate a vision of an infrastructure in three parts: **shared data, shared tools, and shared knowledge.** These domains reflect three of the dominant modes of digital enclosure prerequisite for platform capture: **storage, computation, and communication.** The systems we will describe are in conversation with and a continuation of a long history of reimagining the relationship between these domains for a healthier web (see eg. {% cite berners-leeSociallyAwareCloud2009 berners-leeWebServicesOverview2009 %}). We depart from it to describe a system of fluid, peer-to-peer social affiliation and [folksonomic](#federated-systems-of-language) linked data with lessons primarily from [early wikis and Wikipedia](#the-wiki-way), the fissures of the [semantic web and linked data](#neatness-vs-scruffiness) communities, the social structure of [private bittorrent trackers](#archives-need-communities), and the federation system of [ActivityPub and the Fediverse](#forums--feeds). Approaching this problem from science has its constraints --- like the structuring need to rebuild systems of [credit assignment](#credit-assignment) --- as well as the powerful opportunity of one of the last systems of labor largely not driven by profit developing technology and seeding communities that could begin to directly address the dire, societywide need for digital freedom.

[^nocrypto]: Recently the notion of decentralized digital infrastructure has been co-opted by a variety of swindlers and other motivated parties to refer to blockchain-based technologies like cryptocurrencies, decentralized autonomous organizations, and the like. This work will not discuss them, as their model of artificial scarcity is antithetical to its ethical premises, and they have not been demonstrated to do anything that peer-to-peer technology with adjoining social systems can't do --- except use a colossal quantity of fossil fuels and drain a lot of credulous people's bank accounts.

The problems we face are different than they were at the dawn of the internet, but we can learn from its history: we shouldn't be waiting for a new journal-like **platform,** software package, or subscription to save us. We need to build **protocols** for communication, interoperability, and self-governance (see, recently {% cite brembsReplacingAcademicJournals2021 %}).

I will start with a brief description of what I understand to be the state of our digital infrastructure and the structural barriers and incentives that constrain its development. I will then propose a set of design principles for decentralized infrastructure and possible means of implementing it informed by prior successes and failures at building mass digital infrastructure. I will close with contrasting visions of what science could be like depending on the course of our infrastructuring, and my thoughts on how different actors in the scientific system can contribute to and benefit from decentralization.

I insist that what I will describe is *not utopian* but is eminently practical --- the truly impractical choice is to do nothing and continue to rest the practice of science on a pyramid scheme {% cite ponziSciencePyramidScheme2020 %} of underpaid labor. With a bit of development to integrate and improve the tools, **every class of technology I propose here already exists and is widely used.** A central principle of decentralized systems is embracing heterogeneity: harnessing the power of the diverse ways we do science instead of constraining them. Rather than a patronizing argument that everyone needs to fundamentally alter the way they do science, the systems that I describe are specifically designed to be easily incorporated into existing practices and adapted to variable needs. In this way I argue decentralized systems are *more practical* than the dream that any one system will be capable of expanding to the scale of all science --- and as will hopefully become clear, inarguably *more powerful* than a disconnected sea of centralized platforms and services.

An easy and common misstep is to categorize this as solely a *technical* challenge. Instead the challenge of infrastructure is also *social* and *cultural* --- it involves embedding any technology in a set of social practices, a shared belief that such technology should exist, that its form is not neutral, and a sense of communal valuation and purpose that sustains it {% cite bietzSustainingDevelopmentCyberinfrastructure2012 %}. 

The social and technical perspectives are both essential, but make some conflicting demands on the construction of the piece: Infrastructuring requires considering the interrelatedness and mutual reinforcement of the problems to be addressed, rather than treating them as isolated problems that can be addressed piecemeal with a new package or by founding a new journal alternative. Such a broad scope trades off with a detailed description of the relevant technology and systems, but a myopic techno-zealotry that does not examine the social and ethical nature of scientific practice risks reproducing or creating new sources of harm. That, and techno-solutionism never *works* anyway. As a balance I will not be proposing a complete technical specification or protocol, but describing the general form of the tools and some existing examples that satisfy them; I will not attempt a full history or treatment of the problem of infrastructuring, but provide enough to motivate the form of the proposed implementations. 

My understanding of this problem is, of course, uncorrectably structured by my training largely centered in systems neuroscience and my position as an early career researcher (ECR). While the core of my argument is intended to be a sketch compatible with sciences and knowledge systems generally, my examples will sample from, and my focus will skew to my experience. In many cases, my use of "science" or "scientist" could be "neuroscience" or "neuroscientist," but I will mostly use the former to avoid the constant context switches. This document is also an experiment in public collaboration on a living scientific document: to try and ease our way out of disciplinary tunnelvision, we invite annotation and contribution with no lower bound --- if you'd like to add or correct a sentence or two (or a page or ten), you're welcome as coauthor. I ask the reader for a measure of patience for the many ways this argument requires elaboration and modification for distant fields.