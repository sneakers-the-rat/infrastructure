To get a few big and obvious limitations out of the way first: 
- Everyone could ignore this piece entirely and it is dead on arrival. 
- This project would be a direct threat to some of the most powerful entities in science, and they will likely actively work against it. 
- Despite my best efforts, I could be completely misinformed and missing something fundamental about the underlying technologies. 
- The social tensions between the relevant development communities could be too great to overcome. 

Beyond those, there are several open questions that deserve further consideration, particularly those things concerning cryptography as it is squarely outside my domain of expertise:

**Identity:** Identity is extremely challenging for any decentralized system. An identity needs to be unique, difficult to counterfeit, easy to verify, easy to manage or recover, and also recognizable if not memorable --- and several of these requirements are clearly in conflict. A satisfying resolution of identity will require guidance from cryptographers, but the design of our system has some features that make identity a less-than-intractable problem. The actual raw identifier itself will likely need to be a cryptographic hash of a public key (as in IPFS) for uniqueness and verifiability, but they are very far from memorable. One approach might be to have each peer provide a signed identification object that can be publicly queried with a shorter handle or username, which can then be stored by the peers that follow or befriend them. When peer A refers to peer B's namespace, then, it would be in reference to peer A's follow/friends list. Another approach is to use an RDF-like prefixing idea: in a given context, a short name for a peer's hash is always explicitly declared first before using it. Neither of these are entirely satisfying, and will require a bit of experimentation to get right.

The problem of managing keys and recoverability is also tricky: there's no "forgot password" link if you lose your private key. Since our system is designed to be intrinsically social, we can relax some of the more stringent requirements of zero-trust, totally-anonymous networks like IPFS and lean more on a "web of trust." We might share additional private keys with other peers that we trust to verify or recover our identity, which might be particularly useful in the case of a more stable federation of peers. We want to avoid peers operating like identity systems, as that lends itself to centralization of power and returning to a more activitypub-like style of identity, so it would be a tricky balance. Another strategy might be to use an out-of-band mechanism, like storing a URL in the signed identity object that can be used to update the public key associated with a particular identity -- if you lose yours, you can generate a new keypair and update the public key stored at the URL, which another peer could check to verify that you are who you say you are. These too are not very satisfying, and so more work will be needed to draft a satisfying identity system, the practicality and usability of which will be critical for its success.

**Privacy:** Closely related to identity, in a p2p system any message that isn't intended to be public will need to be encrypted so that secondary peers can't just reshare something we intended to be only for them. In our system, it's not desirable to be able for some data-greedy entity to scrape all the data, we want peers to be able to make friction as-needed. To some degree this is not a solvable problem, as it's always possible to take a screenshot of the most secure end-to-end encrypted chat. It's possible even in analog social systems for secrets to slip, or for people to lie about something that another person said, so arguably the question is how to protect the things that can be verified to be from a person. Another practical problem is communicating which peers are allowed to see something so that a secondary peer knows whether or not they can help seed something: we don't want to have to transmit a list of a thousand peers along with every message, and if they have to ask the primary peer every time then the redundancy of the system is lost. Capability-based security, where permissions for a given object are conferred by having a hard to guess reference to it rather than by checking an easy to guess reference against a permissions list, seems like a good approach (see {% cite conillWhatWouldActivityPub2019 %}). This would look a bit like generating (revocable) sharing links for different groups. Here too we might lean a bit on the social nature of our system, where peers that routinely violate the privacy requirements of other peers can be labeled untrustworthy. 

**Security:** Most parts of this system are relatively low-risk as they are based on metadata that only relies on defined actions programmed into the receiving client --- you don't get viruses merely by torrenting something. Several of the more interesting applications, though, involve a message or link being able to self-identify some code used to run or display it, and whenever you introduce running arbitrary code you introduce significant security risks. This is largely mitigated by our emphasis on non-automaticity: the default for any of these cases should be to *not* do the action. That's cold comfort, though, given the high clickthrough rates for phishing emails. More mitigation can be had by executing code in containers or virtual machines, but that too is not total. We manage to get by extraordinarily well with a very informal reputation system in open source computing. For the most part, people don't think twice about running some Python package without reading the full source code. Our system is one very conducive to [soft security](http://meatballwiki.org/wiki/?SoftSecurity) {% cite meatballwikiSoftSecurity %}, which is based more on accountability and resiliance than strict guarantees of security. Where typically an untrustworthy platform will do whatever it can to avoid people being able to leave comments or talk about it, in our linked data system it's always possible to issue a link saying that something is not to be trustworthy. The ability to mirror shards of our data makes any particular attack more likely to be recoverable, but special care will be needed to ensure the whole network is not subject to rolling waves of ransomware. Like cryptographers, we'll need consultation and input from the infosec crowd to make it safe, but there's nothing intrinsically more dangerous than, say, pip being able to run arbitrary code inside a `setup.py` file.

**RDF Standards:** RDF is highly polarizing, and many people have written it off as a lost cause because it is too complex. Much of the computing world runs off of table and relational databases rather than graphs. Though we tried to be careful to avoid endorsing any particular technology in favor of thinking about triplet links as such, the question of the literal implementation of the standards is an inevitable one. JSON-LD is, thankfully, a relatively humane standard that should be the first point of exploration. We should consider interconvertibility and interoperability with existing standards a top priority of the system in general, so we will need to make interfaces to make it trivial to interact with commonly used formats, even if it is just a wrapper that indicates the format rather than one that can convert it to JSON-LD. Interface design is one of the major missing pieces in the linked data story, and that too should be a top priority so that as little of the system as possible needs to rely on directly interfacing with the underlying data model.

**Performance:** We have more or less explicitly cast performance aside as the wrong thing to optimize for: we want to have *autonomy* more than be able to blaze through the network in microseconds. Still, it's possible for technologies to be so inefficient to be nonfunctional. In a world where we have been conditioned to expect to be able to speak with a manager when our apps are not immediately responsive, or to be able to just buy whatever server performance we want, it will take some collective unlearning to rethink the internet along the lines of cooperatively managed resources. Unlearning performance will take time and has no boardroom-friendly KPIs to measure. There's no reason to believe the system will be slow before it exists, and we ultimately don't imagine this system running from residential connections and personal computers, but being a mixture of institutional and personal resources. Decentralization is a continuum, rather than a binary: we don't have to *ban* large servers from the network, but instead want to make sure that there is a healthy mix so that the system doesn't *depend* on them. This is another place where it is useful to seed this from academia: internet service providers have historically leaned on their oligopolistic control over the underlying hardware of the internet to crush threatening technologies {% cite vandersarComcastThrottlesBitTorrent2007 %}, and we should expect no different this time. We will need to have access to commercial connections, and will likely need to convince our institutions to lobby on our behalf. 

**Manipulation:** What if people lie? What if people purposefully rig the system by seeding it with a bunch of fake data and bad papers? People already lie! People already game the system! What we are hoping to change is to make a system where manipulation isn't built into the system as a self-reinforcing partnership between its proprieters and beneficiaries. The real dangerous thing is a system that *presents* itself as being infallible or neutral through its automaticity and glittering PR campaign. This is why we have baked the social contingency of the system so thoroughly into its design (and should investigate making triplet links into quadruple links with each having an explicit author to make it even more concrete). This is why, I believe, it is so difficult for some people to imagine a world without pre-publication peer review vouched for by a journal: the social contingency of information is scary! It is, however, preferable to the economic contingency of factuality-as-a-service.

The last set of concerns are diffuse rumblings about uptake and whether or not it is even still *possible* to challenge entrenched economic powers in science. It is true that people are cynical, and busy, and some benefit immensely from the present system, and so on. It is also true that we are likely to be met with stiff resistance if we start posing a credible threat to their dominance --- the danger of opposing a set of companies who are the primary data brokers to federal law enforcement agencies, credit rating, and insurance agencies is not lost on me. I don't have any good answers to these sets of questions except that the work from here is about organizing people, adapting and responding to their needs, and making something that is useful enough for even the most complacent to adopt. I don't present this blueprint for infrastructure as infallible, and intend it to be mutated and merged with other ideas as we progress. The only thing that *isn't* an option is doing *nothing.*