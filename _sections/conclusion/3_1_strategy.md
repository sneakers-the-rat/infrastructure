> Don't scab for the bosses / don't listen to their lies / us poor folks haven't got a chance / unless we organize
>
> Which side are you on?
>
> Florence Reece (1931) *Which Side Are You On?*

> **Oh but they will mock us and they will mistreat us til they can replace us all with an app or a kiosk,** [...]
>
> All of the energy that I end up expending, I will get back in spades when the systems that necessitate all of this work fall apart... **And we can work for ourselves for a change!**
> 
> So we gotta work! Cuz none of our visions of a better tomorrow will come to fruition without **a whole lot of work!**
>
> RENT STRIKE (2021) [Work! (Future Perfect)](https://rentstrike.bandcamp.com/track/work-future-perfect-2) {% cite rentstrikeWorkFuturePerfect2021 %}

The primary ingredient needed to build decentralized infrastructure is **will.** The incentive and professional systems of science are designed to make us build our own cage: play along, or lose your job. We need to recognize that *the contemporary practice of science is unsustainable* without radical infrastructural, social, and economic reorganization. As the logic of the digital enclosure movement transforms old enemies into new ones, publishers into surveillance conglomerates, the comfortable familiarity of science as we know it will evaporate into the cloud as we cede control over the direction of our work to for-profit companies with their gamified metrics and platforms that commodify every part of it. The [worst parts](#the-state-of-things) of scientific work are neither natural nor inevitable, but reflect the overwhelming structuring power of orbiting conglomerates. We are *part of this world,* and the world is drowning in an algorithmic sea owned and operated by a rapidly consolidating cluster of information giants. We need to see our place in a shared struggle, the relationship between our deinfrastructuring and the operation of science --- and have the courage to do the work to counteract it.

The work doesn't need to be as dreary as its motivation: rebuilding our infrastructure will be ***joyful.*** We have been starved for social and labor organization, for comradeship and compassion, isolated as we are on our workplace and disciplinary islands, crushed under the weight of cutthroat publish-or-perish schemes, secretive and distrustful from our culture of the heroic individual rushing through the gauntlet of credit before our enemies do. What we might lose in prestige we will regain in collaboration with new and unexpected colleagues building tools to make our work *more fun.* We can trade artificial scarcity for abundance.

### Starting Points

Much of the tactical and strategic vision for our new infrastructure is embedded in its design. We have taken pains to articulate its components as elaborations of existing and widely-used systems, keeping them separable so each can be independently useful before a fuller system is realized, exemplifying them with the real problems that they can remedy. Still, some more scaffolding for how to get there from here is useful. 

The core of our strategy should be to organize alongside each other in a series of independent groups working in parallel. We don't need a new leadership council to become a single point of failure. We should try and organize the many existing groups working in different related areas to pull in the same direction towards interoperability. We should avoid the pitfalls of designing our infrastructures "in theory," building crystal palaces removed from the reality of their use. We should seek to embed in existing projects, using their existing mass to lessen the need to prospect for abstract "early adopters." 

We should look outside our usual circles for collaborators, and there we might find unexpected energy and expertise. Though the miserable academic fleeing to the greener pasture of "industry" is now a well-trod trope, there is plenty of disaffection on the other side. We shouldn't underestimate the number of extremely talented engineers that would do *anything* to not have to build tools so that Facebook can mine your thoughts to target ads {% cite biddleFacebookWonSay2017 %} or maximize the time people spend watching YouTube by recommending them increasingly toxic videos {% cite maackYouTubeRecommendationsAre2019 %}. Academic science is relatively unique in that it can marshal funding and labor for projects not bound to profit. Resources and applications are two potent missing ingredients in developing technologies that are intended to be anti-profitable, and we should work to provide them. We should trawl the places where the decentralized messaging, former semantic web, indieweb, and small tech people are already working on building better infrastructure and invite them to work with us.

The three broad domains of our infrastructure could, but don't necessarily need to, correspond to a division of development labor. The serial order of this piece is primarily a byproduct of the constraint of the medium, and there is no reason we can't proceed in parallel. I want to avoid being too prescriptive here in order to invite input from the many people that might potentially be involved --- the purpose of this document as a pre-development plan is to provide direction and a high-level design so that the details can be sorted out as we work. For the sake of illustration, though I'll drop down from the level of strategy to tactics to flesh out some of the more proximal possibilities for development, but the remainder of this section should be considered non-normative.

A promising context to develop a p2p linked data client is existing collaborations or tools that have a base of users that handle overlapping but variable data. For example, the users or developers of a tool like OpenEphys {% cite siegleOpenEphysOpensource2017 %} or Miniscope {% cite aharoniAllLightThat2019 %} that has [data acquisition software](http://miniscope.org/index.php/Data_Acquisition_Software) that outputs semi-structured data might be interested in making it possible for everyone who uses the tool to share data with one another from the time of acquisition. The situation is similar for other types of tools like analysis tools, or for collaborations where people are sharing data frequently. Since the output data is relatively simple (eg. videos and timestamps) with some variation (eg. configuration and notes), it would be a smaller climb to prototype generating a metadata model linked to the data. Since the group of people that would be sharing data might initially be relatively small with room to grow, the several components of the p2p client could be worked out separately: eg. manually index repositories of metadata from some frontend while figuring out how to strap a git server to a p2p client like hypercore, etc. Being able to be plugged into a group of people sharing data by using a tool might be a reasonably attractive idea to get people to adopt the tool, so it would be worthwhile to the developers while being a useful feature for the users. Being able to do very tight loops of development and field testing might make the tool more robust than if it were developed strictly in-house, and would be a good small-scale demonstration of the utility of p2p.

At the same time, work could happen in the other direction from data standards towards p2p. [Datalad](https://www.datalad.org/) {% cite halchenkoDataLadDistributedSystem2021 %} would be an excellent candidate to add linked data and p2p support to, as it already supports JSON-LD with a [metadata extension](http://docs.datalad.org/projects/metalad/) and has a generalizable data storage backend. In neuroscience, [DANDI](https://dandiarchive.org/) hosts data formatted in NWB, and interoperability with IPFS is on its [development timeline](https://www.dandiarchive.org/#proposed-dandi-timeline). Working from multiple directions towards aligned projects could encourage a small set of modular tools that can accommodate the variation in each of the approaches, and the process would be useful for navigating the fine-scale constraints to the system without putting all of the development eggs in one basket, so to speak.

Aside from p2p, a toolset that's desperately needed across disciplines is an generalizable, approachable means of modeling and ingesting data. The work of building an interface that lets researchers create a JSON-LD metadata model and a declarative description of where that metadata can be located in whatever lab-idiosyncratic format already exists would supplement all other parts of the system. There is no reason for each format to develop a separate schema language and storage mechanism, and this might be one way to spark collaboration between format maintainers.

One of the major reasons for bootstrapping the system with existing formats is to be able encourage analytical and experimental tool interoperability before the means of creating and negotiating over arbitrary schema are developed. This is already starting to happen to a degree in neuroscience with [datajoint elements](https://elements.datajoint.org/) {% cite yatsenkoDataJointElementsData2021 %} and [NWB](https://nwb-overview.readthedocs.io/en/latest/tools/tools_home.html) (see [pynapple](https://github.com/PeyracheLab/pynapple/)), but since the conversion tooling for NWB at the moment is still relatively opaque there isn't strong incentive for analysis libraries to support it for seamless input. A wrapper framework to be able to specify an analysis pipeline from metadata that combines a few of these tools might be useful to kick off the positive feedback loop of analysis toolbuilders building towards interoperability, incentivizing format conversion, etc. 

The other major starting point for development I see is generalizing cellular documents with JSON-LD and mixing them with ActivityPub. With some relatively minor extensions to the jupyter document format we could add the ability to create new cell types with elaborated linked metadata. From there, we could build an ActivityPub client that allows researchers to post their notebooks and invite comment on them in a document/threaded communication medium. The support of an existing organization would be useful here too: they could apply to be a crossref member and make use of the very general specification {% cite isoISO2632420122012 %} such that each post can be given a hierarchical DOI like `doi:10.<registrar>/user/post/version`. Along with the ability to automatically submit to legacy journals with the conversations attached as supplemental material, this might attract a reasonable critical mass towards a model that would make the move towards a p2p document/communication a much smaller step. [Neuromatch](https://neuromatch.io/) {% cite achakulvisutDemocratizingAutomatingOnline2021 kordingLoveNeuroscienceNeuromatch2021 vanviegenNeuromatchAcademyTeaching2021 %} has expressed interest in work in this area, though at the time of writing their plans are still in development.

I'll leave the remainder of the organization project to the work of the future.