#### Trackers, Clients, & Wikis

The final set of social interfaces are those for collective governance of the system. So far we have generalized documents "vertically" into recursive typed cells, "horizontally" into linked cells for communication, and then blurred their independence by and extended them into incompatible media with overlays. The remaining piece we need are multi-authored documents: **wikis**. We'll pick up the threads left hanging from our description of [bittorrent trackers](#archives-need-communities) and knit them in with those from [the wiki way](#the-wiki-way) to describe how systems for surfacing procedural and technical knowledge work can also serve as a basis of searching, indexing, and governing the rest of the system. Where the rest of our interfaces were means of creating particular kinds of structured links, we'll also describe wikis as a means of interacting directly with links to negotiate the relationships between the multiplicity of our folksonomic schema. In the process we'll give some structure to the **clients** and **trackers** that serve and organize them.

Our notion of recursive cell-like documents is already a good basis for wiki pages. **Multi-author** documents should already be possible with a permission system that we have invoked previously to limit read access, and so the most radically open, publicly editable wikis would just have edit permissions open to anyone. The **version history** that makes the notion of [SoftSecurity](http://meatballwiki.org/wiki/SoftSecurity) possible should also be a general property of links in our system. The other concept we'll borrow from traditional wikis is the model where **pages represent topics.** Practically, let's suppose this means that within documents beneath some namespace like `@jonny:wiki`, we can make wikilinks to [[New Pages]] that imply links to `@jonny:wiki:New_Pages` --- though for the sake of simplicity in this section we will assume that our wiki starts at the root of the `@jonny` namespace.

We want to preserve two types of multiplicity: the multiplicity of *representations* (as in `Talk:` pages) and *instances* of a given topic, or the ability for multiple peers to have linked versions that potentially transclude content from other peers, but are ultimately independent. Both can use different components of a namespace: for multiplicity of representation we might follow the example of mediawiki and use parallel namespaces like `@jonny:talk`, and multiplicity of instances follows naturally from parallel peers by linking `@jonny:wiki:My_Page` to `@rumbly:wiki:My_Page`.

Wikis that represent multiple instances of a given page are already a subject of active experimentation. Flancian's Agora is one example, which is based on markdown files in git repositories, and markdown files with the same name in federated repositories are presented on the same page. A much older project[^e2history], [everything2](https://everything2.com/) is built around multiple "[writeups](https://everything2.com/title/Writeup)" for a given "[node](https://everything2.com/title/Node)." Multiple instances of a page are also a defining feature of Ward Cunningham's [federated wiki](http://ward.fed.wiki.org/view/welcome-visitors/view/home-in-the-federation), which has a vertical "strip" based interface where clicking the colored squares at the bottom of a given page will open another strip to show another user's instance of the page. We'll borrow Ward's terminology and refer to this kind of wiki as a federated wiki.

[^e2history]: everything2 (or e2) users tend to be, uh, [floridly sarcastic](https://everything2.com/title/Everything%253A+In+the+Beginning), and so its history is not as clearly laid out as the other old wikilike sites.

Federated wikis already have some broader purchase as "personal knowledge graphs," {% cite balogPersonalKnowledgeGraphs2019 %} where people use tools like [Notion](https://www.notion.so/) or [Obsidian](https://obsidian.md/) to keep a set of linked, semistructured personal notes. Rather than thinking of a wiki as wikipedia, with pages that aspire to be uniformly named and written, personal knowledge graphs take whatever form is useful to the person maintaining them. This maps neatly onto our namespaces and recursive documents as a means of *organizing our system of links.* 

Say we have a very simple project structure that consists of a dataset with two tables and a document with the date of the experiment and some short description of the data. In our pseudocode:

```turtle
<#project>
  a @jonny:Project

  dataset
    @format:csv 
      table1
      table2

  document
    a @jupyter:notebook

    @schema:Date dateCollected
    Description
      "This is the data that I collected"
```

This has a natural representation in our wiki as a set of nested cells: the `@jonny:project` page has two child cells, one for the dataset and one for the document, which have their own child cells that represent the tables, date, and description according to their types. Since the relationships between our cells can also typed, ie. have an associated predicate like `before`, `after`, or `inReplyTo`, we'll use two additional types to differentiate nested cells: 

- `child` (and its inverse `parent`) cells correspond to a cell's position in our namespace, so we could find our data at `@jonny:project:dataset`.
- `transcludes` (and its inverse `transcluded`) indicates some other cell that we represent on a given wiki page, as we might want to do if we wanted to embed one of our plots in a post.
- And other cells linked with bare `[[wikilinks]]` are untyped.

This gives us a bidirectional representation of our link structure: and with it an interface for browsing and managing all the various types of objects that we have described so far. 

Since schemas, or abstract representations of the links a type might have, are themselves made of links, these too can be managed with a wiki. [Semantic mediawiki](https://www.semantic-mediawiki.org/wiki/Semantic_MediaWiki) and its [page schemas](https://www.mediawiki.org/wiki/Extension:Page_Schemas) extension implement a system like this. For example, the [Autopilot wiki](https://wiki.auto-pi-lot.com) has a [form](https://wiki.auto-pi-lot.com/index.php/Form:Build_Guide) to submit build guides for experimental apparatuses. Build guides have a [schema](https://wiki.auto-pi-lot.com/index.php/Category:Construction_Build_Guide) and an associated [template](https://wiki.auto-pi-lot.com/index.php/Template:Build_Guide) that lays out the form input on the created page and makes the semantic wikilinks that declare its properties like `[[Is Version::2]]`. 

This system is semantically rich while also being flexible, as everything reduces down to semantic wikilinks on a page, so free text can be used fluidly along with structured schemas, forms, and templates. The wide open structuring space of the wiki handles the messy iteration of technical knowledge work well while also having enough structure to be computer readable. A page for an [amplifier](https://wiki.auto-pi-lot.com/index.php/HiFiBerry_Amp2) makes the datasheet, serial protocol, and the GPIO pins it needs available via an [API call](https://www.semantic-mediawiki.org/wiki/Help:API) while also carrying on a continuous effort to crudely defeat its low-pass output filter. A [plugin](https://wiki.auto-pi-lot.com/index.php/Plugin:Autopilot_Paper) page can credit the papers it was used in by DOI and the python packages needed to run it while also describing how to void the warranty of your oscilloscope to unlock additional functionality. 

The page-centric model of semantic wikis poses a problem, though. The guide for building the [Autopilot Behavior Box](https://wiki.auto-pi-lot.com/index.php/Autopilot_Behavior_Box) has semantic annotations describing the CAD schematics, materials, and tools that it uses. This works fine for [other assembled parts](https://wiki.auto-pi-lot.com/index.php/Autopilot_Tripoke) or schematics like [3d printed parts](https://wiki.auto-pi-lot.com/index.php/Autopilot_Nosepoke_Cap) that have pages of their own, because their pages can contain the additional properties that describes them like the associated `.stl` files. Materials like screws are trickier. Each screw varies along about a dozen dimensions, and so that either requires making a separate page for each individual screw or use workarounds[^semworkarounds] that reduce the maximum depth of representation to two layers and add other nasty complexities.

[^semworkarounds]: like [subobjects](https://www.semantic-mediawiki.org/wiki/Subobject) or [record types](https://www.semantic-mediawiki.org/wiki/Help:Type_Record)

A recursive cellular system avoids these problems and provides a uniform interface to complex representations. We can create schema for experiments that allow for a build guide, which can contain assembled component descriptions, which can contain materials, etc. When using that schema to describe a new experiment, the researcher can be prompted for any of the possible available fields in the recursive model while also allowing for free space to write in the semi-structure of the building blocks. Extending an existing schema is just a matter of transcluding it and then modifying it as needed. With the ability for our interface to assign fixed IDs for these objects or generate unique hashes based on their contents, the tension of ephemeral object declaration with unique addresses disappears.

The tension of arbitrarily flexible personal knowledge graphs with multiscale organization with other peers remains, though. Approaching from the other side of discovery, rather than declaration of information leads back to considering the structure of our p2p client and tracker-like systems. The most immediate problem we face is the need to reconcile the differences between multiple instantiations of overlapping representations of concepts that change through time. That sounds a lot like version control system, and a VCS like git or mercurial should be a natural part of our client. Where IPFS is "a single bittorrent swarm, exchanging objects within one Git repository," {% cite benetIPFSContentAddressed2014 %} we make a mild modification and think of a single bittorrent swarm with a git repository per peer (also see [IPLD](https://ipld.io/docs/) {% cite protocollabsIPLDDocs2021 %}). Git [stores files](https://git-scm.com/book/en/v2/Git-Internals-Git-Objects) as [content-addressed](https://en.wikipedia.org/wiki/Content-addressable_storage) "blobs" of binary indexed by "trees" that represent the file hierarchy {% cite chaconProGit2020 %}. Our client can do something similar, except using the triplet link structure for trees rather than typical duplet links. Another peer querying our data would then resolve our identity to the top of the tree, our client would then either serve the parts of our tree that the peer has access to or else let them traverse some subsection of it, and they could then request any file "blobs" that the tree points to[^justasketch]. 

[^justasketch]: That's sufficient detail for a sketch, but there is of course a great deal of subtlety that would need to be resolved in an implementation. For example, see {% cite aleksandersenFourP2PDistribution2020 hartgerinkVerifiedSharedModular2019 %}.

By itself this would have a lot of overhead as a large number of peers would need to be queried to find a particular subset of matching metadata. We can mediate that in a few ways. First, our clients could take advantage of the embedded social network to cache and rehost other peer's trees --- either in their entirety or as shards distributed among other peers --- depending on our relationship to them. Second, when making links, we could notify relevant and subscribed peers that we have made it (eg. see {% cite capadisliLinkedDataNotifications2017 %}). Combined with distributed caching, that would allow the peer responsible for the schema to direct queries to peers already known to have a particular kind of file: eg. the `@nwb` peer could track when `@nwb` datasets are declared.

We don't necessarily *want* to have an entirely autonomous protocol though, following the example of wikis and bittorrent trackers we want social systems for shared governance and maintenance of the system. Trackers first serve the technical need of indexing a particular community's data, eg. as [`@dandihub`](https://hub.dandiarchive.org) does with `@nwb`, in case peers go offline. We don't want to just track datasets, however, we want to track the many different kinds of metadata in our swarm. The second role of trackers is collective curation and negotiation over schema. 

Say a group of my colleagues and I organize to set up a server as our tracker. As an interface, our tracker might allow us to browse schemas as a tree. For a given node, we might see "horizontally" across all the schemas that have modifications or extensions to that node, and "vertically" up and down their parent and children nodes. We notice that our colleague has made an extension to a schema that looks very similar to ours. We do a `diff` to see which nodes are similar and which are different between our schema. Both of us have some good ideas that the other doesn't have, so we open a conversation thread by creating a node that references both of our schemas as candidates for merging and send it to our colleague. We negotiate over a way to resolve their differences, similar to a [pull request](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/about-pull-requests), and then `merge` them. Part of our merging process is indicating how to change either of our existing structures to become the third merged structure, so our clients are able to handle those changes for us and the update propagates through the network.

As our tracker grows and maybe even becomes the de-facto tracker for our subdiscipline, things start becoming a bit messier. Aside from the "tree" view for browsing metadata, we've built views that help it function as a forum for threaded conversations and a wiki for organization, tracking projects, and setting policies. The durable but plastic nature of wikis is exceptionally well suited for this. From Butler, Joyce, and Pike (emphasis mine):

> Providing tools and infrastructure mechanisms that support the development and management of policies is an important part of creating social computing systems that work. [...] 
>
> When organizations invest in [collaborative] technologies, [...] their first step is often to put in place a collection of policies and guidelines regarding their use. **However, less attention is given to the policies and guidelines created by the groups that use these systems which are often left to “emerge” spontaneously.** The examples and concepts described in this paper highlight the complexity of rule formation and suggest that support should be provided to help collaborating groups create and maintain effective rulespaces.
> 
> [...] **The true power of wikis lies in the fact that they are a platform that provides affordances which allow for a wide variety of rich, multifaceted organizational structures.** Rather than assuming that rules, policies, and guidelines are operating in only one fashion, wikis allow for, and in fact facilitate, the creation of policies and procedures that serve a wide variety of functions 
>
> *Don't Look Now, But We've Created a Bureaucracy: The Nature and Roles of Policies and Rules in Wikipedia* (2008) {% cite butlerDonLookNow2008 %} 

So we might have a set of policies that encourages a reporting system to notify other peers if their data is misformatted. Or we might reward contribution with a "peer of the week" award that highlights their work like What.cd's album of the week or Wikipedia's [barnstars](https://en.wikipedia.org/wiki/Wikipedia:Barnstars) {% cite wikipediaWikipediaBarnstars2022 %}. We might adopt a cooperative model where each peer pays their share of the server fees, or has to take shifts on moderation and cleanup duty for the week. Each tracker can adopt different policies to reflect their communities. 

Trackers-as-wikis don't have to exist in isolation. Trackers for adjacent disciplines or purposes should be able to federate together to transclude pages: organizing multiple perspectives on the same topic, or supplementing each other into a broader base of knowledge.

What if consensus fails? Our system attempts to mitigate the potential damage of tyrannical moderators by making it extremely easy to *fork.* Since every link in the system "belong" to someone underneath a `@namespace`, links and the schemas they build are always a proposition: "something someone said that I don't necessarily have to agree with." If another peer doesn't like the `merge` that we did, they can fork the previous version and continue using it --- for other peers the link to the merged version lets them translate between them. If we want to jump ship and go find a different tracker that better reflects our values, all our data, including relationships to the people that we liked there, guides we wrote on the wiki, etc. are still our own. The tracker just tracks, it isn't a platform.

Our joint tracker-wikis have many applications for scientific communication, and it's worth exploring a few.
